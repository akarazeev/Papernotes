## Natural Language Processing by DeepHackLab
[![dhl](images/dhl.jpg)](http://info.deephack.me)
### Курс был построен на лекциях by Richard Socher

1. Intro to NLP and Deep Learning [[lecture](https://www.youtube.com/watch?v=sU_Yu_USrNc)]

	- [Трансляция](https://www.youtube.com/watch?v=SkHIbTDrxOQ)
	- [Слайды](http://cs224d.stanford.edu/lectures/CS224d-Lecture1.pdf)
	- Доп. материалы:
		- [Lecture Notes 1](http://cs224d.stanford.edu/lecture_notes/LectureNotes1.pdf)
		- [Linear Algebra Review](http://cs229.stanford.edu/section/cs229-linalg.pdf)
		- [Probability Review](http://cs229.stanford.edu/section/cs229-prob.pdf)
		- [Convex Optimization Review](http://cs229.stanford.edu/section/cs229-cvxopt.pdf)
		- [More Optimization (SGD) Review](http://cs231n.github.io/optimization-1/)
		- [From Frequency to Meaning: Vector Space Models of Semantics](http://www.jair.org/media/2934/live-2934-4846-jair.pdf)
		- [Python Numpy Tutorial](http://cs231n.github.io/python-numpy-tutorial/)

1. Word Vectors [[lecture](https://www.youtube.com/watch?v=xhHOL3TNyJs&feature=youtu.be)]

	- [Слайды](http://cs224d.stanford.edu/lectures/CS224d-Lecture2.pdf)
	- Доп. материалы:
		- [Distributed Representations of Words and Phrases and their Compositionality](http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)
		- [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/pdf/1301.3781.pdf)

1. More Word Vectors [[lecture](https://www.youtube.com/watch?v=UOGMsFw9V_w&list=PLmImxx8Char9Ig0ZHSyTqGsdhb9weEGam&index=3)]

	- [Слайды](http://cs224d.stanford.edu/lectures/CS224d-Lecture3.pdf)
	- Доп. материалы:
		- [Lecture Notes 2](http://cs224d.stanford.edu/lecture_notes/notes2.pdf)
		- [GloVe: Global Vectors for Word Representation](http://nlp.stanford.edu/pubs/glove.pdf)
		- [Improving Word Representations via Global Context and Multiple Word Prototypes](http://www.aclweb.org/anthology/P12-1092)

1. Neural Networks and backpropagation — for named entity recognition [[lecture](https://www.youtube.com/watch?v=bjDbNbSbwY4&list=PLmImxx8Char9Ig0ZHSyTqGsdhb9weEGam&index=4)]

	- [Слайды](http://cs224d.stanford.edu/lectures/CS224d-Lecture4.pdf)
	- Задание: https://github.com/deephacklab/courses/blob/master/NLP/home_work_1/HM1_w2v.ipynb
	- Доп. материалы:
		- [Lecture Notes 3](http://cs224d.stanford.edu/lecture_notes/notes3.pdf)
		- [UFLDL tutorial](http://ufldl.stanford.edu/wiki/index.php/Backpropagation_Algorithm)
		- [Learning Representations by Backpropagating Errors](http://www.iro.umontreal.ca/~vincentp/ift3395/lectures/backprop_old.pdf)

1. Project Advice, Neural Networks and Back-Prop (in full gory detail) [[lecture](https://www.youtube.com/watch?v=k50GPWfjG7I&index=5&list=PLmImxx8Char9Ig0ZHSyTqGsdhb9weEGam)]

	- [Слайды](http://cs224d.stanford.edu/lectures/CS224d-Lecture5.pdf)
	- Доп. материалы:
		- [Natural Language Processing (almost) from Scratch](https://arxiv.org/pdf/1103.0398v1.pdf)
		- [A Neural Network for Factoid Question Answering over Paragraphs](https://cs.umd.edu/~miyyer/pubs/2014_qb_rnn.pdf)
		- [Grounded Compositional Semantics for Finding and Describing Images with Sentences](http://nlp.stanford.edu/~socherr/SocherKarpathyLeManningNg_TACL2013.pdf)
		- [Deep Visual-Semantic Alignments for Generating Image Descriptions](http://cs.stanford.edu/people/karpathy/deepimagesent/devisagen.pdf)
		- [Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank](http://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf)

1. Practical tips: gradient checks, overfitting, regularization, activation functions, details [[lecture](https://www.youtube.com/watch?v=l0k-30FNua8&index=6&list=PLmImxx8Char9Ig0ZHSyTqGsdhb9weEGam)]

	- [Слайды](http://cs224d.stanford.edu/lectures/CS224d-Lecture6.pdf)
	- Доп. материалы:
		- [Practical recommendations for gradient-based training of deep architectures](https://arxiv.org/abs/1206.5533)
		- [UFLDL page on gradient checking](http://ufldl.stanford.edu/wiki/index.php/Gradient_checking_and_advanced_optimization)

1. Recurrent neural networks — for language modeling and other tasks [[lecture](https://www.youtube.com/watch?v=nwcJuGuG-0s&list=PLmImxx8Char9Ig0ZHSyTqGsdhb9weEGam&index=8)]

	- [Слайды](http://cs224d.stanford.edu/lectures/CS224d-Lecture8.pdf)
	- [Доп. лекция по Tensorflow](https://www.youtube.com/watch?v=L8Y2_Cq2X5s&list=PLmImxx8Char9Ig0ZHSyTqGsdhb9weEGam&index=7)
	- [Слайды к доп. лекции](http://cs224d.stanford.edu/lectures/CS224d-Lecture7.pdf)
	- Доп. материалы:
		- [Recurrent neural network based language model](http://www.fit.vutbr.cz/research/groups/speech/publi/2010/mikolov_interspeech2010_IS100722.pdf)
		- [Extensions of recurrent neural network language model](http://www.fit.vutbr.cz/research/groups/speech/publi/2011/mikolov_icassp2011_5528.pdf)
		- [Opinion Mining with Deep Recurrent Neural Networks](http://www.cs.cornell.edu/~oirsoy/drnt.htm)
		- [Tensorflow](https://www.tensorflow.org/versions/r0.11/tutorials/)

1. GRUs and LSTMs — for machine translation [[lecture](https://www.youtube.com/watch?v=OFCuW8VA7A4&index=8&list=PLmImxx8Char8dxWB9LRqdpCTmewaml96q)]

	- [Слайды](http://cs224d.stanford.edu/lectures/CS224d-Lecture9.pdf)
	- Доп. материалы:
		- [Lecture Notes 4](http://cs224d.stanford.edu/lecture_notes/notes4.pdf)
		- [Long Short-Term Memory](http://web.eecs.utk.edu/~itamar/courses/ECE-692/Bobby_paper1.pdf)
		- [Gated Feedback Recurrent Neural Networks](https://arxiv.org/pdf/1502.02367v3.pdf)
		- [Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling](https://arxiv.org/pdf/1412.3555v1.pdf)

1. Convolutional neural networks – for sentence classification [[lecture](https://www.youtube.com/watch?v=EevTPpQvxiU&index=11&list=PLmImxx8Char8dxWB9LRqdpCTmewaml96q) **Note: RNN here stands for Recursive NN not for Recurrent NN*]
	- [Слайды](http://cs224d.stanford.edu/lectures/CS224d-Lecture13.pdf)
	- Доп. материалы:
		- [A Convolutional Neural Network for Modelling Sentences](https://www.nal.ai/papers/Kalchbrenner_DCNN_ACL14)

1. Applications of DL in NLP [[lecture](https://www.youtube.com/watch?v=BVbQRrrsJo0&list=PLmImxx8Char8dxWB9LRqdpCTmewaml96q&index=12) **Note: RNN here stands for Recursive NN not for Recurrent NN*]
